{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eager Execution\n",
    "\n",
    "Sources:\n",
    "- [1] https://www.tensorflow.org/programmers_guide/eager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check to see eager execution is running\n",
    "tf.executing_eagerly()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorf objects now reference actual values rather than symbolic handles to graph nodes\n",
    "x = [[2.]]\n",
    "x = tf.matmul(x, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'The output is {x}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.constant([[1, 2], [3, 4]])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = tf.add(a, 1)\n",
    "c = tf.multiply(b, a)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can also use numpy with tensors\n",
    "import numpy as np\n",
    "c = np.multiply(a, b)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the numpy property from a tensor\n",
    "a.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a custom layer inheriting from the keras layers class\n",
    "class SimpleLayer(tf.keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self, num_outputs):\n",
    "        self.num_outputs = num_outputs\n",
    "        \n",
    "    def build(self, input):\n",
    "        # Gets called the first time the layer is used\n",
    "        self.kernel = self.add_variable(\"kernel\", [input.shape[-1], self.num_outputs]) # Input shape dependent\n",
    "    \n",
    "    def call(self, input):\n",
    "        return tf.matmul(input, self.kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can build models with layers by using the Sequential class in keras\n",
    "simple_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10, input_shape=(784,)),\n",
    "    tf.keras.layers.Dense(10)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build models by inherting from the keras Model class\n",
    "class SimpleModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.layer1 = tf.keras.layers.Dense(10) # Don't need to define input shape due to superclass init\n",
    "        self.layer2 = tf.keras.layers.Dense(10)\n",
    "        \n",
    "    def call(self, input):\n",
    "        layer1_out = self.layer1(input)\n",
    "        layer2_out = self.layer2(layer1_out)\n",
    "        return layer2_out\n",
    "    \n",
    "simple_model = SimpleModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eager Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfe = tf.contrib.eager\n",
    "w = tfe.Variable([[1.0]])\n",
    "\n",
    "# All forward pass operations get recorded to a tape\n",
    "with tf.GradientTape() as tape:\n",
    "    loss = w * w\n",
    "    \n",
    "# Play tape backwards to get gradient (tapes can only be used once)\n",
    "grad = tape.gradient(loss, [w])\n",
    "grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A Simple example using gradient tape\n",
    "\n",
    "# A bunch of points randomly spaced around 3*x + 2\n",
    "NUM_EXAMPLES = 1000\n",
    "training_input = tf.random_normal([NUM_EXAMPLES])\n",
    "noise = tf.random_normal([NUM_EXAMPLES])\n",
    "training_output = 3 * training_input + 2 + noise\n",
    "\n",
    "# Simple prediction\n",
    "def prediction(input, weight, bias):\n",
    "    return input * weight + bias\n",
    "\n",
    "def loss(weights, biases):\n",
    "    # Use mse as the loss\n",
    "    error = prediction(training_input, weights, biases) - training_output\n",
    "    return tf.reduce_mean(tf.square(error))\n",
    "\n",
    "# Use gradient tape to return derivative of loss\n",
    "def grad(weights, biases):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss_value = loss(weights, biases)\n",
    "    return tape.gradient(loss_value, [weights, biases])\n",
    "\n",
    "train_steps = 100\n",
    "learning_rate = 0.01\n",
    "# Initialize arbitrary weight and bias\n",
    "W = tfe.Variable(5.)\n",
    "b = tfe.Variable(10.)\n",
    "\n",
    "print(f'Initial loss {loss(W, b)}')\n",
    "\n",
    "# Train\n",
    "for i in range(train_steps):\n",
    "    dW, db = grad(W, b)\n",
    "    W.assign_sub(dW * learning_rate) # Assign and subtract learning rate times gradient\n",
    "    b.assign_sub(db * learning_rate)\n",
    "    print(f'Step {i} loss {loss(W, b)}')\n",
    "\n",
    "print(f'Final values: W = {W.numpy()}, b = {b.numpy()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.W = tfe.Variable(5., name='weights')\n",
    "        self.B = tfe.Variable(10., name='bias')\n",
    "    def predict(self, input):\n",
    "        return self.W * input + self.B\n",
    "    \n",
    "# Loss and Gradient functions defined with respect to model\n",
    "def loss(model, inputs, targets):\n",
    "    error = model.predict(inputs) - targets\n",
    "    return tf.reduce_mean(tf.square(error))\n",
    "\n",
    "def grad(model, inputs, targets):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss_value = loss(model, inputs, targets)\n",
    "    return tape.gradient(loss_value, [model.W, model.B])\n",
    "\n",
    "# Lets create the model and train it\n",
    "model = Model()\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "train_steps = 100\n",
    "\n",
    "for i in range(100):\n",
    "    grads = grad(model, training_input, training_output)\n",
    "    optimizer.apply_gradients(zip(grads, [model.W, model.B]),\n",
    "                             global_step=tf.train.get_or_create_global_step())\n",
    "    print(f'Loss at step {i} is {loss(model, training_input, training_output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objects for State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables are object and can be un-assigned to remove from memory\n",
    "with tf.device('cpu:0'):\n",
    "    v = tfe.Variable(tf.random_normal([10, 10]))\n",
    "    v = None    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save and restore variables with checkpoints\n",
    "x = tfe.Variable(10.)\n",
    "\n",
    "checkpoint = tfe.Checkpoint(x=x)\n",
    "save_path = checkpoint.save('./ckpt/')\n",
    "print(save_path)\n",
    "\n",
    "# modify value of varibale\n",
    "x.assign(4.)\n",
    "print(x)\n",
    "\n",
    "# Restore\n",
    "checkpoint.restore(save_path)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
